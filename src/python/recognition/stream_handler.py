import numpy as np
import time

class StreamHandler:
    """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë° íŠ¹ì„± ì¶”ì¶œ"""
    
    def __init__(self, model, sample_rate=16000, chunk_size=1024):
        """
        ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            model: ONNX ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
            sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ê¸°ë³¸ê°’: 16kHz)
            chunk_size: ì²˜ë¦¬í•  ì²­í¬ í¬ê¸°
        """
        self.model = model
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        
        # ìƒíƒœ ë° ë²„í¼ ë³€ìˆ˜
        self.buffer = []
        self.features = []
        self.is_active = False
        self.total_samples = 0
        self.start_time = None
        self.last_inference_time = 0
        self.inference_interval = 0.5  # ì¶”ë¡  ê°„ê²©(ì´ˆ)
    
    def start(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œì‘"""
        print("ğŸ”„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œì‘")
        self.buffer = []
        self.features = []
        self.is_active = True
        self.total_samples = 0
        self.start_time = time.time()
        self.last_inference_time = 0
        return True
    
    def process_chunk(self, audio_chunk):
        """ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ë° ì‹¤ì‹œê°„ ì¶”ë¡ """
        if not self.is_active:
            return None
        
        try:
            # ì…ë ¥ ë°ì´í„° ë³€í™˜
            if not isinstance(audio_chunk, np.ndarray):
                audio_chunk = np.array(audio_chunk, dtype=np.float32)
            
            # int16 -> float32 ë³€í™˜
            if audio_chunk.dtype != np.float32:
                if audio_chunk.dtype == np.int16:
                    audio_chunk = audio_chunk.astype(np.float32) / 32768.0
                else:
                    audio_chunk = audio_chunk.astype(np.float32)
            
            # ë³¼ë¥¨ ì •ë³´ (ë””ë²„ê¹…ìš©)
            volume = np.abs(audio_chunk).mean()
            print(f"ğŸ¤ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ : {len(audio_chunk)} ìƒ˜í”Œ, í‰ê·  ë³¼ë¥¨: {volume:.4f}")
            
            # ì˜¤ë””ì˜¤ ë²„í¼ì— ì²­í¬ ì¶”ê°€
            self.buffer.append(audio_chunk)
            self.total_samples += len(audio_chunk)
            
            # íŠ¹ì„± ì¶”ì¶œ
            from ..audio.feature_extractor import FeatureExtractor
            features = FeatureExtractor.extract_features(audio_chunk)
            
            # ìœ íš¨í•œ íŠ¹ì„±ì¸ì§€ í™•ì¸
            if features is not None and features.shape[0] > 0:
                self.features.append(features)
                
                # ì‹¤ì‹œê°„ ì¶”ë¡  ì‹¤í–‰ (ì¶”ê°€ëœ ë¶€ë¶„)
                current_time = time.time()
                if current_time - self.last_inference_time >= self.inference_interval:
                    print("â±ï¸ ì‹¤ì‹œê°„ ì¶”ë¡  ê°„ê²© ë„ë‹¬, ì¶”ë¡  ì‹¤í–‰...")
                    self.last_inference_time = current_time
                    result = self._perform_realtime_inference()
                    return result
                
                return features
            else:
                print("âš ï¸ ìœ íš¨í•œ íŠ¹ì„±ì´ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
            
        except Exception as e:
            print(f"âŒ ì²­í¬ ì²˜ë¦¬ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _perform_realtime_inference(self):
        """ì‹¤ì‹œê°„ ëª¨ë¸ ì¶”ë¡  ìˆ˜í–‰"""
        print(f"ğŸ”„ ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œì‘ (ë²„í¼: {len(self.buffer)} ì²­í¬, íŠ¹ì„±: {len(self.features)}ê°œ)")
        
        # ìµœê·¼ íŠ¹ì„± ë°ì´í„° ì‚¬ìš©
        if len(self.features) > 0:
            try:
                # íŠ¹ì„± ëŒ€ì‹  ì›ì‹œ ì˜¤ë””ì˜¤ ë°ì´í„° ì‚¬ìš©
                recent_audio = np.concatenate(self.buffer[-3:], axis=0)  # ìµœê·¼ 3ê°œ ì²­í¬ë§Œ ì‚¬ìš©
                print(f"ì˜¤ë””ì˜¤ ë°ì´í„° í¬ê¸°: {recent_audio.shape}")
                
                # ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
                if self.model and hasattr(self.model, 'infer'):
                    # ì˜¤ë””ì˜¤ ë°ì´í„° ì§ì ‘ ì „ë‹¬ (íŠ¹ì„± ëŒ€ì‹ )
                    result = self.model.infer(recent_audio)
                    print(f"âœ… ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ")
                    return {"success": True}  # ì„ì‹œ ê²°ê³¼
            
            except Exception as e:
                print(f"âš ï¸ ì‹¤ì‹œê°„ ì¶”ë¡  ì˜¤ë¥˜: {e}")
        
        return None
    
    def stop(self):
        """
        ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¢…ë£Œ
        
        Returns:
            all_features: ì „ì²´ íŠ¹ì„± ë°°ì—´
        """
        if not self.is_active:
            print("âš ï¸ ì´ë¯¸ ì¤‘ì§€ëœ ìŠ¤íŠ¸ë¦¼ì…ë‹ˆë‹¤.")
            return np.array([])
        
        self.is_active = False
        duration = time.time() - self.start_time
        print(f"âœ… ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì™„ë£Œ: ì´ {self.total_samples} ìƒ˜í”Œ, {duration:.2f}ì´ˆ")
        
        # ìµœì¢… ë²„í¼ ì²˜ë¦¬
        if not self.buffer:
            print("âš ï¸ ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return np.array([])
        
        # ëª¨ë“  ì˜¤ë””ì˜¤ ë°ì´í„° ê²°í•©
        try:
            all_audio = np.concatenate(self.buffer, axis=0)
            print(f"ğŸ” ê²°í•©ëœ ì˜¤ë””ì˜¤ í¬ê¸°: {all_audio.shape}")
            
            # íŠ¹ì„±ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ ì˜¤ë””ì˜¤ì—ì„œ ì¶”ì¶œ
            if not self.features:
                from ..audio.feature_extractor import FeatureExtractor
                all_features = FeatureExtractor.extract_features(all_audio)
            else:
                # ëª¨ë“  íŠ¹ì„± ê²°í•©
                all_features = np.concatenate(self.features, axis=0)
            
            print(f"ğŸ” ìµœì¢… íŠ¹ì„± í¬ê¸°: {all_features.shape}")
            
            # ìµœì¢… ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
            if self.model and hasattr(self.model, 'infer'):
                try:
                    result = self.model.infer(all_features)
                    print(f"âœ… ìµœì¢… ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ: ê²°ê³¼ í˜•íƒœ {result.shape if hasattr(result, 'shape') else 'ì•Œ ìˆ˜ ì—†ìŒ'}")
                    
                    # CTC í™•ë¥  ë¶„í¬ ê³„ì‚°
                    from ..recognition.ctc_decoder import CTCDecoder
                    ctc_probs = CTCDecoder.get_probabilities(all_features)
                    
                    # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
                    return {
                        "features": all_features,
                        "ctc_probs": ctc_probs,
                        "is_final": True,
                        "timestamp": duration
                    }
                    
                except Exception as e:
                    print(f"âš ï¸ ìµœì¢… ì¶”ë¡  ì˜¤ë¥˜: {e}")
            
            return all_features
            
        except Exception as e:
            print(f"âŒ ìµœì¢… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return np.array([])
    
    def get_buffer_duration(self):
        """í˜„ì¬ ë²„í¼ì˜ ì˜¤ë””ì˜¤ ê¸¸ì´(ì´ˆ)"""
        if not self.total_samples:
            return 0.0
        return self.total_samples / self.sample_rate
    
    def reset(self):
        """ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”"""
        self.buffer = []
        self.features = []
        self.is_active = False
        self.total_samples = 0
        self.start_time = None
        self.last_inference_time = 0
        self.inference_interval = 0.5  # ì¶”ë¡  ê°„ê²©(ì´ˆ)
        print("ğŸ”„ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”ë¨")